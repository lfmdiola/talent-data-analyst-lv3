{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ST IT Cloud - Data and Analytics Test LV.3\n",
    "\n",
    "Esse teste deve avaliar a qualidade técnica na manipulacão de dados.\n",
    "\n",
    "## Passo a passo\n",
    "\n",
    "- Disponibilizamos aqui 1 case para ser solucionado, leia os enunciados dos problemas, desenvolva os programas, utilizando a **stack definida durante o processo seletivo**, para entregar os dados de acordo com os requisitos descritos abaixo.\n",
    "\n",
    "\n",
    "**Faz parte dos critérios de avaliacão a pontualidade da entrega. Implemente até onde for possível dentro do prazo acordado.**\n",
    "\n",
    "**Os dados de pessoas foram gerados de forma aleatória, utilizando a biblioteca FakerJS, FakerJS-BR e Faker**\n",
    "\n",
    "LEMBRE-SE: A entrega deve conter TODOS os passos para o avaliador executar o programa (keep it simple).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTE PRÁTICO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problema**: Você está recebendo o arquivo 'dados_cadastrais_fake.csv' que contem dados cadastrais de clientes, mas para que análises ou relatórios sejam feitos é necessário limpar e normalizar os dados. Além disso, existe uma coluna com o número de cpf e outra com cnpj, você precisará padronizar deixando apenas dígitos em formato string (sem caracteres especiais), implementar uma forma de verificar se tais documentos são válidos sendo que a informação deve se adicionada ao dataframe em outras duas novas colunas.\n",
    "\n",
    "Após a normalização, gere reports que respondam as seguintes perguntas:\n",
    "- Quantos clientes temos nessa base?\n",
    "- Qual a média de idade dos clientes?\n",
    "- Quantos clientes nessa base pertencem a cada estado?\n",
    "- Quantos CPFs válidos e inválidos foram encontrados?\n",
    "- Quantos CNPJs válidos e inválidos foram encontrados?\n",
    "\n",
    "Ao final gere um arquivo no formato csv e um outro arquivo no formato parquet chamado (problema1_normalizado), eles serão destinados para pessoas distintas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, countDistinct, udf\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"teste\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Função de validação do dígito do CPF\n",
    "def valida_cpf(cpf):\n",
    "\tpesos_dv_1 = [10, 9, 8, 7, 6, 5, 4, 3, 2]\n",
    "\tpesos_dv_2 = [11, 10, 9, 8, 7, 6, 5, 4, 3, 2]\n",
    "\n",
    "\tcpf_len = len(cpf)\n",
    "\tcpf_sem_dv = cpf[:-2]\n",
    "\tcpf_origin_dv_1 = cpf[9]\n",
    "\tcpf_origin_dv_2 = cpf[10]\n",
    "\n",
    "\n",
    "\t### Validacao primeiro digito verificador\n",
    "\tsoma_dv_1 = sum([peso * int(n) for peso, n in zip(pesos_dv_1, cpf_sem_dv)])\n",
    "\tresto_dv_1 = soma_dv_1 % 11\n",
    "\tdv_1 = 0 if resto_dv_1 in [0, 1] else 11 - resto_dv_1\n",
    "\tdv_1 = str(dv_1)\n",
    "\n",
    "\t### Validacao segundo digito verificador\n",
    "\tcpf_dv_1 = f\"{cpf_sem_dv}{dv_1}\"\n",
    "\tsoma_dv_2 = sum([peso * int(n) for (peso, n) in zip(pesos_dv_2, cpf_dv_1)])\n",
    "\tresto_dv_2 = soma_dv_2 % 11\n",
    "\tdv_2 = 0 if resto_dv_2 in [0,1] else 11 - resto_dv_2\n",
    "\tdv_2 = str(dv_2)\n",
    "\n",
    "\tcpf_validado = f\"{cpf_sem_dv}{dv_1}{dv_2}\"\n",
    "\t# print(cpf_validado)\n",
    "\n",
    "\tif ((cpf_len == 11) and (dv_1 == cpf_origin_dv_1) and (dv_2 == cpf_origin_dv_2)):\n",
    "            return \"Válido\"\n",
    "\telse:\n",
    "            return \"Inválido\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Função de validação do dígito do CNPJ\n",
    "def valida_cnpj(cnpj):\n",
    "\tpesos_dv_1 = [5, 4, 3, 2, 9, 8, 7, 6, 5, 4, 3, 2]\n",
    "\tpesos_dv_2 = [6, 5, 4, 3, 2, 9, 8, 7, 6, 5, 4, 3, 2]\n",
    "\n",
    "\tcnpj_len = len(cnpj)\n",
    "\tcnpj_sem_dv = cnpj[:-2]\n",
    "\tcnpj_origin_dv_1 = cnpj[12]\n",
    "\tcnpj_origin_dv_2 = cnpj[13]\n",
    "\n",
    "\n",
    "\t### Validacao primeiro digito verificador\n",
    "\tsoma_dv_1 = sum([peso * int(n) for peso, n in zip(pesos_dv_1, cnpj_sem_dv)])\n",
    "\tresto_dv_1 = soma_dv_1 % 11\n",
    "\tdv_1 = 0 if resto_dv_1 in [0, 1] else 11 - resto_dv_1\n",
    "\tdv_1 = str(dv_1)\n",
    "\n",
    "\t### Validacao segundo digito verificador\n",
    "\tcnpj_dv_1 = f\"{cnpj_sem_dv}{dv_1}\"\n",
    "\t\n",
    "\tsoma_dv_2 = sum([peso * int(n) for (peso, n) in zip(pesos_dv_2, cnpj_dv_1)])\n",
    "\tresto_dv_2 = soma_dv_2 % 11\n",
    "\tdv_2 = 0 if resto_dv_2 in [0,1] else 11 - resto_dv_2\n",
    "\tdv_2 = str(dv_2)\n",
    "\n",
    "\tcnpj_validado = f\"{cnpj_sem_dv}{dv_1}{dv_2}\"\n",
    "\n",
    "\tif ((cnpj_len == 14) and (dv_1 == cnpj_origin_dv_1) and (dv_2 == cnpj_origin_dv_2)):\n",
    "\t\treturn \"Válido\" \n",
    "\telse:\n",
    "\t\treturn \"Inválido\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Leitura do arquivo csv\n",
    "df = spark.read.format(\"csv\").options(header = 'true', inferSchema = 'true', sep = ';').load(\"dados_cadastrais_fake.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remoção de pontos, vírgulas e barras dos cnpjs\n",
    "df_trata_cnpj = df.withColumn(\"cnpj\",regexp_replace(col(\"cnpj\"), \"[\\\\.,\\\\-,\\\\/]\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remoção de pontos, vírgulas e barras dos cpfs\n",
    "df_tratado = df_trata_cnpj.withColumn(\"cpf\",regexp_replace(col(\"cpf\"), \"[\\\\.,\\\\-,\\\\/]\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Padronização dos estados\n",
    "df_estado = df_tratado.withColumn('estado', regexp_replace('estado', 'são  paulo', 'SP'))\n",
    "df_estado = df_estado.withColumn('estado', regexp_replace('estado', 'sao  paulo', 'SP'))\n",
    "df_estado = df_estado.withColumn('estado', regexp_replace('estado', 'MINAS GERAIs', 'MG'))\n",
    "df_estado = df_estado.withColumn('estado', regexp_replace('estado', 'MINAS GERAI', 'MG'))\n",
    "df_estado = df_estado.withColumn('estado', regexp_replace('estado', 'distrito federal', 'DF'))\n",
    "df_estado = df_estado.withColumn('estado', regexp_replace('estado', 'rio de  janeiro ', 'RJ'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Padronização dos estados e cidades - Primeira letra maiúscula\n",
    "df_trata_nome = df_estado.withColumn(\"nomes\", f.initcap(f.col(\"nomes\")))\n",
    "df_trata_cidade = df_trata_nome.withColumn(\"cidade\", f.initcap(f.col(\"cidade\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Chamada a função que valida o cpf\n",
    "call_valida_cpf = udf(lambda x: valida_cpf(x), StringType())\n",
    "df_cpf_validado = df_trata_cidade.withColumn(\"StatusCPF\", call_valida_cpf(df_trata_cidade.cpf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Chamada a função que valida o cnpj\n",
    "call_valida_cnpj = udf(lambda x: valida_cnpj(x), StringType())\n",
    "df_final = df_cpf_validado.withColumn(\"StatusCNPJ\", call_valida_cnpj(df_cpf_validado.cnpj))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantos clientes tem na base?\n",
    "- Fiz o calculo baseado na quantidade de números de cpf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|Qtde Clientes|\n",
      "+-------------+\n",
      "|        10000|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_final.select(countDistinct(\"cpf\").alias(\"Qtde Clientes\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qual a media de idade dos clientes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|Media idade|\n",
      "+-----------+\n",
      "|    53.7831|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_final.agg(f.avg(col('idade')).alias(\"Media idade\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantos clientes nessa base pertencem a cada estado?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|estado|count|\n",
      "+------+-----+\n",
      "|    SC|  370|\n",
      "|    RO|  370|\n",
      "|    PI|  370|\n",
      "|    AM|  371|\n",
      "|    RR|  370|\n",
      "|    GO|  371|\n",
      "|    TO|  370|\n",
      "|    MT|  370|\n",
      "|    SP|  370|\n",
      "|    ES|  371|\n",
      "|    PB|  370|\n",
      "|    RS|  370|\n",
      "|    MS|  370|\n",
      "|    AL|  371|\n",
      "|    MG|  370|\n",
      "|    PA|  370|\n",
      "|    BA|  371|\n",
      "|    SE|  370|\n",
      "|    PE|  370|\n",
      "|    CE|  371|\n",
      "|    RN|  370|\n",
      "|    RJ|  370|\n",
      "|    MA|  371|\n",
      "|    AC|  371|\n",
      "|    DF|  371|\n",
      "|    PR|  370|\n",
      "|    AP|  371|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_final.groupBy('estado').count().show(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantos CPFs válidos e inválidos foram encontrados?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|StatusCPF|count|\n",
      "+---------+-----+\n",
      "|   Válido|10000|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_final.groupBy('StatusCPF').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantos CNPJs válidos e inválidos foram encontrados?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|StatusCNPJ|count|\n",
      "+----------+-----+\n",
      "|    Válido|10000|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_final.groupBy('StatusCNPJ').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Salvando o arquivo em formato csv\n",
    "df_final.write.option(\"header\",True).mode(\"overwrite\").csv(\"clientes_csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Salvando o arquivo em formato parquet\n",
    "df_final.write.option(\"header\",True).mode(\"overwrite\").parquet(\"clientes_parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
